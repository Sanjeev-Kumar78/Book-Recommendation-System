{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import opendatasets as od\n",
    "\n",
    "# Load dataset into a Pandas DataFrame\n",
    "od.download(\"https://drive.usercontent.google.com/download?id=1dDd2Kr9wxE44jARLPG_ysZjOHjeoKOLw&export=download&authuser=1&confirm=t&uuid=aee55275-8452-44f4-8a74-ad70554e1c79&at=APZUnTUB5u7-vOVHH3U0wHBtiDZ3%3A1708431658128\")\n",
    "data = pd.read_csv(\"GoodReads_100k.csv\")\n",
    "\n",
    "\n",
    "# Remove duplicates from df\n",
    "data = data.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle outliers (e.g., filter unrealistic ratings)\n",
    "data = data[(data['rating'] >= 1) & (data['rating'] <= 5)]\n",
    "\n",
    "# print(len(data))\n",
    "# data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['isbn','title','author','rating','reviews','img','desc','genre','pages']]\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns={'isbn':'ISBN','title':'Title','link':'Link','author':'Author','rating':'Rating','reviews':'No. of ratings','img':'Image','desc':'Desc','genre':'Genre','pages':'Pages'},inplace=True)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum() # no. of null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(subset=['Genre'])\n",
    "data = data.dropna(subset=['Desc'])\n",
    "data = data.dropna(subset=['Image'])\n",
    "data = data.dropna(subset=['ISBN'])\n",
    "print(len(data))\n",
    "print(\"____________________________________\")\n",
    "\n",
    "data = data.reset_index(drop=True)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = data[data['No. of ratings'] >= 100]\n",
    "print(len(final_data))\n",
    "print(\"_____________\")\n",
    "final_data = final_data.reset_index(drop=True)\n",
    "final_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Models Used for Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "# # Create a TF-IDF Vectorizer for the 'desc' column\n",
    "# tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "\n",
    "# # To check Output from above code: \n",
    "# # print(f\"Final Data Null Values: {final_data['Desc'].isnull().sum()}\")\n",
    "# # print(f\"Lenght of Final Data: {len(final_data)}\")\n",
    "\n",
    "# # print(f\"TfidfVectorizer: {tfidf_vectorizer}\")\n",
    "\n",
    "\n",
    "# # Replace NaN values with an empty string\n",
    "# final_data['Desc'] = final_data['Desc'].fillna('')\n",
    "\n",
    "# # Apply the TF-IDF vectorizer to the 'desc' column\n",
    "# tfidf_matrix_desc = tfidf_vectorizer.fit_transform(final_data['Desc'])\n",
    "\n",
    "# # print(f\"tfidf_matrix_desc: {tfidf_matrix_desc}\") # To check Output from above code\n",
    "\n",
    "\n",
    "# # Convert the data type to float32\n",
    "# tfidf_matrix_desc = tfidf_matrix_desc.astype(np.float32)\n",
    "# # print(f\"tfidf_matrix_desc: {tfidf_matrix_desc}\") # To check Output from above code\n",
    "\n",
    "\n",
    "# # Compute the cosine similarity matrix for book descriptions\n",
    "# cosine_sim_desc = linear_kernel(tfidf_matrix_desc, tfidf_matrix_desc)\n",
    "# # print(f\"cosine_sim_desc: {cosine_sim_desc}\") # To check Output from above code\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check Output from above code: \n",
    "print(f\"Final Data Null Values: {final_data['Desc'].isnull().sum()}\")\n",
    "print(f\"Lenght of Final Data: {len(final_data)}\")\n",
    "print(\"_______________________\")\n",
    "# print(f\"Length of Cosine_Similarity: {len(cosine_sim_desc)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recommendation Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. `tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=10000)`: This line creates a TF-IDF (Term Frequency-Inverse Document Frequency) vectorizer. This is a technique used to quantify a word in documents, we generally compute a weight to each word which signifies the importance of the word in the document and corpus. The vectorizer is set to ignore common English stop words (like 'the', 'is', 'and', etc.) and only consider the top 10,000 features ordered by term frequency across the corpus.\n",
    "\n",
    "2. `final_data['Desc'] = final_data['Desc'].fillna('',inplace=True)`: This line replaces any NaN (Not a Number) values in the 'Desc' column of the final_data DataFrame with an empty string.\n",
    "\n",
    "3. `tfidf_matrix_desc = tfidf_vectorizer.fit_transform(final_data['Desc'])`: This line applies the TF-IDF vectorizer to the 'Desc' column of the final_data DataFrame. The `fit_transform` function learns the vocabulary and idf, and returns a term-document matrix.\n",
    "\n",
    "4. `tfidf_matrix_desc = tfidf_matrix_desc.astype(np.float32)`: This line converts the data type of the tfidf_matrix_desc to float32. This is done to reduce memory usage.\n",
    "\n",
    "5. `cosine_sim_desc = linear_kernel(tfidf_matrix_desc, tfidf_matrix_desc)`: This line computes the cosine similarity matrix for book descriptions. Cosine similarity is a measure of similarity between two non-zero vectors of an inner product space that measures the cosine of the angle between them.\n",
    "\n",
    "6. `def get_recommendations(book_title, cosine_sim)`: This line defines a function named get_recommendations that takes a book title and a cosine similarity matrix as input.\n",
    "\n",
    "7. `if not final_data.empty:`: This line checks if the final_data DataFrame is empty. If it is not empty, the code inside the if block is executed.\n",
    "\n",
    "8. `idx = final_data[final_data['Title'] == book_title].index`: This line gets the index of the book that matches the input book title.\n",
    "\n",
    "9. `if len(idx) > 0:`: This line checks if the book title exists in the DataFrame. If it does, the code inside the if block is executed.\n",
    "\n",
    "10. `idx = idx[0]`: This line gets the first index from the idx list.\n",
    "\n",
    "11. `sim_scores = list(enumerate(cosine_sim[idx]))`: This line creates a list of tuples where the first element is the index and the second element is the cosine similarity score.\n",
    "\n",
    "12. `sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)`: This line sorts the list of tuples based on the cosine similarity score in descending order.\n",
    "\n",
    "13. `sim_scores = sim_scores[1:11]`: This line gets the top 10 tuples from the sorted list.\n",
    "\n",
    "14. `book_indices = [i[0] for i in sim_scores]`: This line gets the indices of the top 10 tuples.\n",
    "\n",
    "15. `return final_data['Title'].iloc[book_indices]`: This line returns the titles of the books that correspond to the top 10 indices.\n",
    "\n",
    "16. `else: return \"Book not found\"`: If the book title does not exist in the DataFrame, the function returns \"Book not found\".\n",
    "\n",
    "17. `else: return \"No data available\"`: If the final_data DataFrame is empty, the function returns \"No data available\".\n",
    "\n",
    "18. `get_recommendations('The Art of Love', cosine_sim_desc)`: This line calls the get_recommendations function with 'The Art of Love' as the book title and cosine_sim_desc as the cosine similarity matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Recommendation Function Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get book recommendations based on book title\n",
    "def get_recommendations(book_title, cosine_sim):\n",
    "\n",
    "    # Check if the final_data DataFrame is empty\n",
    "    if not final_data.empty:\n",
    "        # Get the index of the book title\n",
    "        idx = final_data[final_data['Title'] == book_title].index\n",
    "        # print(f\"idx: {idx}\") # Output check\n",
    "        if len(idx) > 0:\n",
    "            idx = idx[0]\n",
    "            sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "            # print(f\"sim_scores: {sim_scores}\") # Output check\n",
    "            sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "            sim_scores = sim_scores[1:11]\n",
    "            # print(f\"sim_scores top 10: {sim_scores}\") # Output check\n",
    "            book_indices = [i[0] for i in sim_scores]\n",
    "            # print(f\"book_indices: {book_indices}\") # Output check\n",
    "            # return book title with image url and author\n",
    "            return final_data[['Title', 'Image', 'Author','Pages']].iloc[book_indices]\n",
    "        else:\n",
    "            return \"Book not found\"\n",
    "    else:\n",
    "        return \"No data available\"\n",
    "    \n",
    "# get_recommendations(\"Happiness: Lessons from a New Science\",cosine_sim_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Models\n",
    "- cosine_sim_desc\n",
    "- final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# save cosine_sim_desc\n",
    "# pickle.dump(cosine_sim_desc,open('model/cosine_sim_desc.pkl',\"wb\"), protocol=4)\n",
    "\n",
    "# save final_data\n",
    "# pickle.dump(final_data,open(\"model/final_data.pkl\",\"wb\"))\n",
    "\n",
    "# save final_data as csv\n",
    "final_data.to_csv(\"model/final_data.csv\",index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
